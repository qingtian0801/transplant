肝移植

=========================================================================

一、1_xlsx_to_csv文件夹

1、data.py

给定的数据为xlsx形式的，并且有多个sheet，我们在这里是将每一个sheet拆分成一个csv文件。

=========================================================================

二、2_data_merge文件夹

1、all_data.py

将all_data.py文件中拆分出来的多个csv文件合并成一个csv文件，合并依据是[姓名、序列号、病案号、ID号]。将合并后的csv文件我们称为all_data.csv。

=========================================================================

三、3_data_deal文件夹

1、data_deal.py

数据预处理阶段

直接删除无关特征：序列号、姓名等这些都对预测没有影响；血型（A-B等）、诊断、并发症，因为是重复特征，后边还有特征为one-hot编码形式的特征；术前条码_x_y，POD_n条码是空的；

=========================================================================

一般情况表：删除了序列号，姓名，病案号，ID号，联系电话，血型，诊断，并发症等这些特征。

序列号、姓名等这些都对预测没有影响；血型（A-B等）、诊断、并发症，因为是重复特征，后边还有特征为one-hot编码形式的特征；

==========================================================================

血常规表：术前条码_x，一直到POD14_x（条码），

==========================================================================

生化表：术前条码_y，一直到POD14_y（条码）,

==========================================================================

血气表：门脉开放时间_n和术前时间点，都是日期（年月日时分秒），以下的都是时间。

```
'门脉开放时间_x','术前时间点','开放前时间点','距开放时间-0(min)','开放10min内','距开放时间-10(min)','开放30min内','距开放时间-30(min)','开放30-60min','距开放时间-60(min)','开放60-90min内','距开放时间-90(min)','开放90-120min内','距开放时间-120(min)','开放120-150min内','距开放时间-150(min)','开放150-180min内','距开放时间-180(min)','开放180-210min内','距开放时间-210(min)','开放210-240min内','距开放时间-240(min)','术毕','距开放时间-end(min)','入ICU','距开放时间-icu(min)','术后1天','距开放时间-1d(min)','距开放时间-1d(h)','术后2天','距开放时间-2d(min)','距开放时间-2d(h)'
```

主要：检测身体各个值的含量。

距开放时间-0(min)：特征为开放前时间点—门脉开放时间的差值。

==========================================================================

```
'术前条码','术后条码','POD1条码','POD2条码','POD3条码','POD4条码','POD5条码','POD6条码','POD7条码','POD14条码'
```

凝血表：大部分为空，所以删除。

==========================================================================

```
'手术开始日期_x','手术结束日期','门脉阻断时间','门脉开放时间_y'
```

术中情况表：日期格式直接删除。

=========================================================================

术中化验：这个表缺失值达到百分之八十以上，直接删除。

=========================================================================

```
'手术开始日期_y','POD0日期','最后记录日期','最后记录天数d'，'最后记录状态','自动离院原因','术后30天存活1死亡2','术后90天存活1死亡2','术后180天存活1死亡2','术后1年存活1死亡2',
    '出院后情况'
```

总体转归表：日期格式直接删除。术后那些为大量缺失，直接删除。

=========================================================================

```
'手术结束时刻','拔管时刻','术后带管时间h','ICU驻留时间d','术后住院时间d','术后住院转归(1康复出院2死亡3自动离院)','术后死亡时间d','术后自动离院时间d','死亡或放弃治疗原因','具体情况.3','具体情况.9'
```

出院前后术后转归：

手术结束时刻，拔管时刻：都是日期格式直接删除。

术后带管时间，ICU驻留时间，一直到术后住院转归：都是时间数据，对用药没啥关系。

术后死亡时间d和术后自动离院时间d：大量缺失直接删除。

**死亡或放弃治疗原因**：字符型数据，暂时删除，后续再进行one-hot编码。

=========================================================================

**drop_feature**：这个列表里的都是字符型数据，暂时不做处理，后续再进行处理。

=========================================================================

for循环

=========================================================================



如果特征缺失值在80%以上的，进行删除。否则的话，如果该特征的均值在0.5-1之间，则缺失值填充为1；如果该特征值的均值在0-0.5之间，则缺失值填充为0；否则该特征缺失值直接填充为均值。

最终的保存数据的csv文件称为all_data_last.csv



=========================================================================



四、4_feature_importance文件夹

1、importance_pick.py

选取术后并发症I   术后并发症II    术后并发症IIIa   术后并发症IIIb   术后并发症IV  术后并发症 V 其它并发症作为y    用xgboost算法对特征进行重要性的提取，并返回特征的索引号。（此时的维度为374）



=========================================================================



五、5_model文件夹

1、Naive.py

采用了高斯朴素贝叶斯模型对数据进行预测，得到错误率为38.2%左右。

2、SMOTE + Naive_Bayes.py

采用了数据增强技术和朴素贝叶斯的结合，得到错误率为23.4%左右（目前最好）

3、PCA + Naive_Bayes.py

考虑用pca降维技术和朴素贝叶斯的结合，效果并不是很好，得到错误率为46%左右

自己的理解：PCA 本质上是做线性维度“缩减”，在最大化保留信息的目标下，用一个更短的向量表达
一个更长的向量的信息，这必定带来信息弱化和损失。PCA 效率的一般度量既是方差比率，数据精度都已经被损失掉了，还想保有原来的效果，当然违背常理（尤其是降维导致方差下降很多的时候）。

4、KPCA + Naive_Bayes .py

又继续尝试了kpca和朴素贝叶斯的结合，得到错误率为24%左右（与数据增强+朴素贝叶斯相近）

5、SMOTE +KPCA + Naive_Bayes .py

在考虑将三者结合进行预测，反而效果很不好，得到错误率为56.5%左右。

自己理解：数据在用PCA降维的时候，效果不是很好，但是用KPCA的效果很好，说明我们的数据属于非线性数据，并非线性数据，而使用SMOTE的时候，效果很好，单独使用KPCA的时候效果也不错，但是SMOTE+KPCA时候，效果有所下降，原因在于SMOTE是使用线性插值方法，而KPCA是非线性的，所以两者叠加，有可能达不到我们期望的1+1>2的效果。